{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3229fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "      MODE DEBUGGING: NONAKTIF\n",
      "==================================================\n",
      "--- Tes Ketersediaan GPU PyTorch ---\n",
      "Apakah CUDA tersedia? -> True\n",
      "GPU terdeteksi: NVIDIA GeForce RTX 5060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmdet.utils import register_all_modules\n",
    "import os\n",
    "\n",
    "DEBUG_MODE = False  # Set to True for debugging mode\n",
    "print(\"=\"*50)\n",
    "print(f\"      MODE DEBUGGING: {'AKTIF' if DEBUG_MODE else 'NONAKTIF'}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ===== Step 1: Setup & Registrasi =====\n",
    "register_all_modules()\n",
    "\n",
    "print(\"--- Tes Ketersediaan GPU PyTorch ---\")\n",
    "print(f\"Apakah CUDA tersedia? -> {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU terdeteksi: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"PERINGATAN: Tidak ada GPU terdeteksi. Training akan berjalan di CPU dan akan sangat lambat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ce75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INFO: Memilih model backbone Swin Transformer ---\n",
      "--- INFO: Model yang digunakan: retinanet ---\n",
      "--- INFO: Mendefinisikan ulang pipeline untuk train dan validasi ---\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 2: Load Konfigurasi Model (RetinaNet) =====\n",
    "print(\"--- INFO: Memilih model backbone Swin Transformer ---\")\n",
    "#untuk retinanet\n",
    "cfg_path = 'mmdetection/configs/swin/retinanet_swin-t-p4-w7_fpn_1x_coco.py' \n",
    "#untuk faster-rcnn\n",
    "# cfg_path = 'mmdetection/configs/swin/faster-rcnn_swin-t-p4-w7_fpn_1x_coco.py'\n",
    "cfg = Config.fromfile(cfg_path)\n",
    "\n",
    "# Ambil nama model dari path config\n",
    "model_name = None\n",
    "if \"retinanet\" in cfg_path.lower():\n",
    "    model_name = \"retinanet\"\n",
    "elif \"faster-rcnn\" in cfg_path.lower():\n",
    "    model_name = \"fasterrcnn\"\n",
    "else:\n",
    "    model_name = \"custommodel\"\n",
    "\n",
    "print(f\"--- INFO: Model yang digunakan: {model_name} ---\")\n",
    "\n",
    "# ===== [FIX FINAL] Definisikan Ulang Pipeline dengan Benar =====\n",
    "print(\"--- INFO: Mendefinisikan ulang pipeline untuk train dan validasi ---\")\n",
    "\n",
    "# Definisikan pipeline untuk training\n",
    "# Kita pastikan 'LoadAnnotations' tidak memuat mask\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile', backend_args=None),\n",
    "    dict(type='LoadAnnotations', with_bbox=True, with_mask=False), # Pastikan with_mask=False\n",
    "    dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "     dict(\n",
    "        type='Normalize',\n",
    "        mean=[123.675, 116.28, 103.53],   # mean ImageNet\n",
    "        std=[58.395, 57.12, 57.375],      # std ImageNet\n",
    "        to_rgb=True\n",
    "    ),\n",
    "    dict(type='PackDetInputs'),\n",
    "]\n",
    "\n",
    "# Definisikan pipeline untuk validasi dan tes\n",
    "# KUNCI UTAMA ADA DI SINI: pastikan 'scale_factor' ada di 'meta_keys'\n",
    "val_pipeline = [\n",
    "    dict(type='LoadImageFromFile', backend_args=None),\n",
    "    dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
    "    # `LoadAnnotations` dibutuhkan untuk evaluasi\n",
    "    dict(type='LoadAnnotations', with_bbox=True, with_mask=False), # Pastikan with_mask=False\n",
    "    dict(\n",
    "        type='PackDetInputs',\n",
    "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
    "                   'scale_factor')) # PASTIKAN 'scale_factor' ADA DI SINI\n",
    "]\n",
    "\n",
    "# Terapkan pipeline yang sudah didefinisikan\n",
    "cfg.train_dataloader.dataset.pipeline = train_pipeline\n",
    "cfg.val_dataloader.dataset.pipeline = val_pipeline\n",
    "cfg.test_dataloader.dataset.pipeline = val_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7840fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INFO: Menggunakan file anotasi training: annotations/instances_train.json\n",
      "--- INFO: Menggunakan file anotasi validasi: annotations/instances_valid.json\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 3: Modifikasi Konfigurasi Dataset (dengan Logika Debug) =====\n",
    "data_root = 'Dataset/Deepfish_COCO/'\n",
    "metainfo = {'classes': ('Fish',), 'palette': [(220, 20, 60)]}\n",
    "\n",
    "# Pilih file anotasi berdasarkan DEBUG_MODE\n",
    "train_ann_file = 'annotations/mini_instances_train.json' if DEBUG_MODE else 'annotations/instances_train.json'\n",
    "val_ann_file = 'annotations/mini_instances_valid.json' if DEBUG_MODE else 'annotations/instances_valid.json'\n",
    "print(f\"--- INFO: Menggunakan file anotasi training: {train_ann_file}\")\n",
    "print(f\"--- INFO: Menggunakan file anotasi validasi: {val_ann_file}\")\n",
    "\n",
    "# Terapkan konfigurasi dataset\n",
    "cfg.train_dataloader.dataset.update(dict(\n",
    "    data_root=data_root, metainfo=metainfo, ann_file=train_ann_file,\n",
    "    data_prefix=dict(img='train/'), filter_cfg=dict(filter_empty_gt=True)))\n",
    "cfg.val_dataloader.dataset.update(dict(\n",
    "    data_root=data_root, metainfo=metainfo, ann_file=val_ann_file,\n",
    "    data_prefix=dict(img='valid/'), filter_cfg=dict(filter_empty_gt=True)))\n",
    "cfg.test_dataloader.dataset.update(dict(\n",
    "    data_root=data_root, metainfo=metainfo, ann_file=val_ann_file,\n",
    "    data_prefix=dict(img='valid/'), filter_cfg=dict(filter_empty_gt=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504c6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Step 4: Modifikasi Evaluator COCO =====\n",
    "cfg.val_evaluator.ann_file = data_root + val_ann_file\n",
    "cfg.test_evaluator.ann_file = data_root + val_ann_file\n",
    "cfg.val_evaluator.metric = 'bbox'\n",
    "cfg.test_evaluator.metric = 'bbox'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e09a2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Step 5: Atur Kepala Model Deteksi (Model Head) =====\n",
    "# Untuk RetinaNet, head-nya berbeda dari Faster R-CNN\n",
    "# cfg.model.bbox_head.num_classes = 1\n",
    "\n",
    "\n",
    "\n",
    "if hasattr(cfg.model, 'bbox_head'):\n",
    "    cfg.model.bbox_head.num_classes = 1\n",
    "elif hasattr(cfg.model, 'roi_head'):\n",
    "    if isinstance(cfg.model.roi_head.bbox_head, list):\n",
    "        for head in cfg.model.roi_head.bbox_head:\n",
    "            head.num_classes = 1\n",
    "    else:\n",
    "        cfg.model.roi_head.bbox_head.num_classes = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9235dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INFO: Learning rate diatur secara eksplisit ke 0.0001 ---\n",
      "--- INFO: Tidak ada checkpoint ditemukan. Memulai training dari awal. ---\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 6: Atur Pengaturan Training (Training Settings) =====\n",
    "\n",
    "cfg.optim_wrapper.optimizer.lr = 0.0001\n",
    "print(f\"--- INFO: Learning rate diatur secara eksplisit ke {cfg.optim_wrapper.optimizer.lr} ---\")\n",
    "\n",
    "if not DEBUG_MODE: # Hanya resume jika tidak dalam mode debug\n",
    "    checkpoint_file = './outputs_swin_retinanet_deepfish/epoch_10.pth' # atau latest.pth\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        print(f\"--- INFO: Menemukan checkpoint. Akan melanjutkan training dari {checkpoint_file} ---\")\n",
    "        cfg.load_from = checkpoint_file\n",
    "        cfg.resume = True # <-- INI DIA TEMPATNYA\n",
    "    else:\n",
    "        # Jika tidak ada checkpoint, pastikan resume False (default)\n",
    "        print(\"--- INFO: Tidak ada checkpoint ditemukan. Memulai training dari awal. ---\")\n",
    "        cfg.resume = False\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "if DEBUG_MODE:\n",
    "    cfg.train_cfg.max_epochs = 10\n",
    "    cfg.default_hooks.logger.interval = 5\n",
    "    cfg.default_hooks.checkpoint.interval = 1\n",
    "    print(\"--- INFO: Pengaturan training dipercepat untuk mode debug.\")\n",
    "else:\n",
    "    cfg.train_cfg.max_epochs = 15 # Atau lebih\n",
    "    cfg.default_hooks.logger.interval = 10\n",
    "    cfg.default_hooks.checkpoint.interval = 1\n",
    "\n",
    "# Pengaturan checkpoint lainnya\n",
    "cfg.default_hooks.checkpoint.max_keep_ckpts = 3\n",
    "cfg.default_hooks.checkpoint.save_best = 'coco/bbox_mAP'\n",
    "cfg.default_hooks.checkpoint.rule = 'greater'\n",
    "cfg.visualizer.vis_backends = [\n",
    "    dict(type='LocalVisBackend'),\n",
    "    dict(type='TensorboardVisBackend')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdb7aac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INFO: Hasil akan disimpan di folder: ./outputs_swin_retinanet_deepfish ---\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 7: Tentukan Direktori Output =====\n",
    "# ===== Step 7: Tentukan Direktori Output (Otomatis sesuai model) =====\n",
    "work_dir_base = f'./outputs_swin_{model_name}_deepfish'\n",
    "cfg.work_dir = f\"{work_dir_base}_debug\" if DEBUG_MODE else work_dir_base\n",
    "print(f\"--- INFO: Hasil akan disimpan di folder: {cfg.work_dir} ---\")\n",
    "os.makedirs(cfg.work_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e3c39f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pengecekan Dataset Final ---\n",
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Jumlah data training yang akan digunakan: 3596\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Jumlah data validasi yang akan digunakan: 909\n",
      "---------------------------------\n",
      "\n",
      "Konfigurasi selesai. Siap untuk menjalankan training di sel berikutnya.\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 8: Verifikasi Dataset Final (Sanity Check) =====\n",
    "from mmengine.registry import DATASETS\n",
    "\n",
    "print(\"\\n--- Pengecekan Dataset Final ---\")\n",
    "try:\n",
    "    train_dataset = DATASETS.build(cfg.train_dataloader.dataset)\n",
    "    print(f\"Jumlah data training yang akan digunakan: {len(train_dataset)}\")\n",
    "    val_dataset = DATASETS.build(cfg.val_dataloader.dataset)\n",
    "    print(f\"Jumlah data validasi yang akan digunakan: {len(val_dataset)}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nFATAL ERROR saat memuat dataset: {e}\")\n",
    "    # Gunakan `raise` di notebook agar error terlihat jelas\n",
    "    raise e\n",
    "print(\"---------------------------------\\n\")\n",
    "\n",
    "print(\"Konfigurasi selesai. Siap untuk menjalankan training di sel berikutnya.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb0236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Memulai proses training...\n",
      "08/26 18:23:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.10.18 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:08:55) [MSC v.1929 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 111036196\n",
      "    GPU 0: NVIDIA GeForce RTX 5060\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\n",
      "    NVCC: Cuda compilation tools, release 12.8, V12.8.61\n",
      "    MSVC: n/a, reason: fileno\n",
      "    PyTorch: 2.8.0+cu128\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 201703\n",
      "  - MSVC 193833145\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2025.2-Product Build 20250620 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_100,code=sm_100;-gencode;arch=compute_120,code=sm_120\n",
      "  - CuDNN 91.0.2  (built against CUDA 12.9)\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=a1cb3cc05d46d198467bebbb6e8fba50a325d4e7, CUDA_VERSION=12.8, CUDNN_VERSION=9.10.2, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/pytorch/.ci/pytorch/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, USE_XCCL=OFF, USE_XPU=OFF, \n",
      "\n",
      "    TorchVision: 0.23.0+cu128\n",
      "    OpenCV: 4.12.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 111036196\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/26 18:23:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/coco/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=1,\n",
      "        max_keep_ckpts=3,\n",
      "        rule='greater',\n",
      "        save_best='coco/bbox_mAP',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        attn_drop_rate=0.0,\n",
      "        convert_weights=True,\n",
      "        depths=[\n",
      "            2,\n",
      "            2,\n",
      "            6,\n",
      "            2,\n",
      "        ],\n",
      "        drop_path_rate=0.2,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=96,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth',\n",
      "            type='Pretrained'),\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            3,\n",
      "            6,\n",
      "            12,\n",
      "            24,\n",
      "        ],\n",
      "        out_indices=(\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_norm=True,\n",
      "        qk_scale=None,\n",
      "        qkv_bias=True,\n",
      "        type='SwinTransformer',\n",
      "        window_size=7,\n",
      "        with_cp=False),\n",
      "    bbox_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            octave_base_scale=4,\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales_per_octave=3,\n",
      "            strides=[\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "                128,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            alpha=0.25,\n",
      "            gamma=2.0,\n",
      "            loss_weight=1.0,\n",
      "            type='FocalLoss',\n",
      "            use_sigmoid=True),\n",
      "        num_classes=1,\n",
      "        stacked_convs=4,\n",
      "        type='RetinaHead'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        add_extra_convs='on_input',\n",
      "        in_channels=[\n",
      "            192,\n",
      "            384,\n",
      "            768,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        start_level=0,\n",
      "        type='FPN'),\n",
      "    test_cfg=dict(\n",
      "        max_per_img=100,\n",
      "        min_bbox_size=0,\n",
      "        nms=dict(iou_threshold=0.5, type='nms'),\n",
      "        nms_pre=1000,\n",
      "        score_thr=0.05),\n",
      "    train_cfg=dict(\n",
      "        allowed_border=-1,\n",
      "        assigner=dict(\n",
      "            ignore_iof_thr=-1,\n",
      "            min_pos_iou=0,\n",
      "            neg_iou_thr=0.4,\n",
      "            pos_iou_thr=0.5,\n",
      "            type='MaxIoUAssigner'),\n",
      "        debug=False,\n",
      "        pos_weight=-1,\n",
      "        sampler=dict(type='PseudoSampler')),\n",
      "    type='RetinaNet')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.0001, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=12,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            8,\n",
      "            11,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "pretrained = 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_valid.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='valid/'),\n",
      "        data_root='Dataset/Deepfish_COCO/',\n",
      "        filter_cfg=dict(filter_empty_gt=False),\n",
      "        metainfo=dict(classes=('Fish', ), palette=[\n",
      "            (\n",
      "                220,\n",
      "                20,\n",
      "                60,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='Dataset/Deepfish_COCO/annotations/instances_valid.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='train/'),\n",
      "        data_root='Dataset/Deepfish_COCO/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(classes=('Fish', ), palette=[\n",
      "            (\n",
      "                220,\n",
      "                20,\n",
      "                60,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_valid.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='valid/'),\n",
      "        data_root='Dataset/Deepfish_COCO/',\n",
      "        filter_cfg=dict(filter_empty_gt=True),\n",
      "        metainfo=dict(classes=('Fish', ), palette=[\n",
      "            (\n",
      "                220,\n",
      "                20,\n",
      "                60,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='Dataset/Deepfish_COCO/annotations/instances_valid.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='TensorboardVisBackend'),\n",
      "    ])\n",
      "work_dir = './outputs_swin_retinanet_deepfish'\n",
      "\n",
      "08/26 18:23:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/26 18:23:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=1.89s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "08/26 18:23:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by http backend from path: https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth\n",
      "08/26 18:23:34 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/26 18:23:34 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "08/26 18:23:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to c:\\Users\\Stevenstven\\Documents\\VSCode\\Skripsi\\Deteksi_Jenis_Ikan\\outputs_swin_retinanet_deepfish.\n",
      "08/26 18:23:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][  10/1798]  lr: 1.9018e-06  eta: 0:42:41  time: 1.4328  data_time: 0.9346  memory: 5211  loss: 1.7877  loss_cls: 1.1309  loss_bbox: 0.6568\n",
      "08/26 18:23:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][  20/1798]  lr: 3.9038e-06  eta: 0:27:12  time: 0.9183  data_time: 0.4689  memory: 5210  loss: 1.7872  loss_cls: 1.1313  loss_bbox: 0.6560\n",
      "08/26 18:23:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][  30/1798]  lr: 5.9058e-06  eta: 0:22:02  time: 0.7482  data_time: 0.3136  memory: 5210  loss: 1.7910  loss_cls: 1.1311  loss_bbox: 0.6599\n",
      "08/26 18:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][  40/1798]  lr: 7.9078e-06  eta: 0:19:33  time: 0.6673  data_time: 0.2360  memory: 5210  loss: 1.7901  loss_cls: 1.1312  loss_bbox: 0.6589\n",
      "08/26 18:24:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][  50/1798]  lr: 9.9098e-06  eta: 0:18:02  time: 0.6190  data_time: 0.1895  memory: 5210  loss: 1.7897  loss_cls: 1.1311  loss_bbox: 0.6586\n",
      "08/26 18:24:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][  60/1798]  lr: 1.1912e-05  eta: 0:17:01  time: 0.4186  data_time: 0.0035  memory: 5210  loss: 1.7882  loss_cls: 1.1311  loss_bbox: 0.6570\n",
      "08/26 18:24:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][  70/1798]  lr: 1.3914e-05  eta: 0:16:15  time: 0.4227  data_time: 0.0035  memory: 5210  loss: 1.7879  loss_cls: 1.1309  loss_bbox: 0.6570\n",
      "08/26 18:24:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][  80/1798]  lr: 1.5916e-05  eta: 0:15:38  time: 0.4253  data_time: 0.0035  memory: 5210  loss: 1.7878  loss_cls: 1.1311  loss_bbox: 0.6567\n",
      "08/26 18:24:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][  90/1798]  lr: 1.7918e-05  eta: 0:15:07  time: 0.4230  data_time: 0.0035  memory: 5210  loss: 1.7885  loss_cls: 1.1311  loss_bbox: 0.6574\n",
      "08/26 18:24:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 100/1798]  lr: 1.9920e-05  eta: 0:14:42  time: 0.4204  data_time: 0.0034  memory: 5210  loss: 1.7857  loss_cls: 1.1313  loss_bbox: 0.6544\n",
      "08/26 18:24:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 110/1798]  lr: 2.1922e-05  eta: 0:14:20  time: 0.4167  data_time: 0.0032  memory: 5210  loss: 1.7887  loss_cls: 1.1313  loss_bbox: 0.6574\n",
      "08/26 18:24:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 120/1798]  lr: 2.3924e-05  eta: 0:14:01  time: 0.4131  data_time: 0.0032  memory: 5210  loss: 1.7868  loss_cls: 1.1313  loss_bbox: 0.6555\n",
      "08/26 18:24:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 130/1798]  lr: 2.5926e-05  eta: 0:13:43  time: 0.4096  data_time: 0.0031  memory: 5210  loss: 1.7846  loss_cls: 1.1310  loss_bbox: 0.6536\n",
      "08/26 18:24:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 140/1798]  lr: 2.7928e-05  eta: 0:13:28  time: 0.4078  data_time: 0.0032  memory: 5210  loss: 1.7828  loss_cls: 1.1308  loss_bbox: 0.6520\n",
      "08/26 18:24:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 150/1798]  lr: 2.9930e-05  eta: 0:13:13  time: 0.4057  data_time: 0.0032  memory: 5210  loss: 1.7829  loss_cls: 1.1306  loss_bbox: 0.6522\n",
      "08/26 18:24:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 160/1798]  lr: 3.1932e-05  eta: 0:13:01  time: 0.4041  data_time: 0.0031  memory: 5210  loss: 1.7816  loss_cls: 1.1304  loss_bbox: 0.6512\n",
      "08/26 18:24:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 170/1798]  lr: 3.3934e-05  eta: 0:12:49  time: 0.4040  data_time: 0.0031  memory: 5210  loss: 1.7839  loss_cls: 1.1306  loss_bbox: 0.6534\n",
      "08/26 18:24:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 180/1798]  lr: 3.5936e-05  eta: 0:12:38  time: 0.4039  data_time: 0.0031  memory: 5210  loss: 1.7875  loss_cls: 1.1306  loss_bbox: 0.6568\n",
      "08/26 18:25:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 190/1798]  lr: 3.7938e-05  eta: 0:12:28  time: 0.4038  data_time: 0.0030  memory: 5210  loss: 1.7880  loss_cls: 1.1307  loss_bbox: 0.6573\n",
      "08/26 18:25:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 200/1798]  lr: 3.9940e-05  eta: 0:12:18  time: 0.4042  data_time: 0.0030  memory: 5210  loss: 1.7912  loss_cls: 1.1305  loss_bbox: 0.6607\n",
      "08/26 18:25:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 210/1798]  lr: 4.1942e-05  eta: 0:12:09  time: 0.4040  data_time: 0.0030  memory: 5210  loss: 1.7901  loss_cls: 1.1305  loss_bbox: 0.6596\n",
      "08/26 18:25:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 220/1798]  lr: 4.3944e-05  eta: 0:12:01  time: 0.4060  data_time: 0.0031  memory: 5210  loss: 1.7933  loss_cls: 1.1303  loss_bbox: 0.6630\n",
      "08/26 18:25:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 230/1798]  lr: 4.5946e-05  eta: 0:11:54  time: 0.4098  data_time: 0.0031  memory: 5210  loss: 1.7896  loss_cls: 1.1301  loss_bbox: 0.6595\n",
      "08/26 18:25:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 240/1798]  lr: 4.7948e-05  eta: 0:11:48  time: 0.4131  data_time: 0.0033  memory: 5210  loss: 1.7904  loss_cls: 1.1300  loss_bbox: 0.6604\n",
      "08/26 18:25:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 250/1798]  lr: 4.9950e-05  eta: 0:11:40  time: 0.4148  data_time: 0.0032  memory: 5210  loss: 1.7880  loss_cls: 1.1300  loss_bbox: 0.6580\n",
      "08/26 18:25:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 260/1798]  lr: 5.1952e-05  eta: 0:11:33  time: 0.4161  data_time: 0.0032  memory: 5210  loss: 1.7875  loss_cls: 1.1299  loss_bbox: 0.6576\n",
      "08/26 18:25:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 270/1798]  lr: 5.3954e-05  eta: 0:11:26  time: 0.4121  data_time: 0.0031  memory: 5210  loss: 1.7844  loss_cls: 1.1298  loss_bbox: 0.6545\n",
      "08/26 18:25:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 280/1798]  lr: 5.5956e-05  eta: 0:11:18  time: 0.4064  data_time: 0.0030  memory: 5210  loss: 1.7851  loss_cls: 1.1298  loss_bbox: 0.6553\n",
      "08/26 18:25:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 290/1798]  lr: 5.7958e-05  eta: 0:11:11  time: 0.4015  data_time: 0.0029  memory: 5210  loss: 1.7864  loss_cls: 1.1296  loss_bbox: 0.6568\n",
      "08/26 18:25:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 300/1798]  lr: 5.9960e-05  eta: 0:11:04  time: 0.3979  data_time: 0.0029  memory: 5210  loss: 1.7856  loss_cls: 1.1295  loss_bbox: 0.6562\n",
      "08/26 18:25:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 310/1798]  lr: 6.1962e-05  eta: 0:10:58  time: 0.3989  data_time: 0.0029  memory: 5210  loss: 1.7824  loss_cls: 1.1295  loss_bbox: 0.6529\n",
      "08/26 18:25:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 320/1798]  lr: 6.3964e-05  eta: 0:10:53  time: 0.4036  data_time: 0.0030  memory: 5210  loss: 1.7817  loss_cls: 1.1292  loss_bbox: 0.6526\n",
      "08/26 18:25:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 330/1798]  lr: 6.5966e-05  eta: 0:10:47  time: 0.4089  data_time: 0.0030  memory: 5210  loss: 1.7815  loss_cls: 1.1290  loss_bbox: 0.6525\n",
      "08/26 18:26:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 340/1798]  lr: 6.7968e-05  eta: 0:10:42  time: 0.4141  data_time: 0.0030  memory: 5210  loss: 1.7811  loss_cls: 1.1290  loss_bbox: 0.6521\n",
      "08/26 18:26:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 350/1798]  lr: 6.9970e-05  eta: 0:10:37  time: 0.4193  data_time: 0.0031  memory: 5210  loss: 1.7804  loss_cls: 1.1287  loss_bbox: 0.6516\n",
      "08/26 18:26:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 360/1798]  lr: 7.1972e-05  eta: 0:10:32  time: 0.4199  data_time: 0.0032  memory: 5210  loss: 1.7817  loss_cls: 1.1284  loss_bbox: 0.6532\n",
      "08/26 18:26:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 370/1798]  lr: 7.3974e-05  eta: 0:10:26  time: 0.4192  data_time: 0.0031  memory: 5210  loss: 1.7779  loss_cls: 1.1283  loss_bbox: 0.6496\n",
      "08/26 18:26:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 380/1798]  lr: 7.5976e-05  eta: 0:10:21  time: 0.4187  data_time: 0.0030  memory: 5210  loss: 1.7727  loss_cls: 1.1281  loss_bbox: 0.6446\n",
      "08/26 18:26:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 390/1798]  lr: 7.7978e-05  eta: 0:10:16  time: 0.4189  data_time: 0.0031  memory: 5210  loss: 1.7669  loss_cls: 1.1278  loss_bbox: 0.6391\n",
      "08/26 18:26:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 400/1798]  lr: 7.9980e-05  eta: 0:10:11  time: 0.4183  data_time: 0.0030  memory: 5210  loss: 1.7693  loss_cls: 1.1278  loss_bbox: 0.6414\n",
      "08/26 18:26:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 410/1798]  lr: 8.1982e-05  eta: 0:10:06  time: 0.4171  data_time: 0.0029  memory: 5210  loss: 1.7779  loss_cls: 1.1277  loss_bbox: 0.6503\n",
      "08/26 18:26:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 420/1798]  lr: 8.3984e-05  eta: 0:10:00  time: 0.4149  data_time: 0.0029  memory: 5210  loss: 1.7799  loss_cls: 1.1277  loss_bbox: 0.6522\n",
      "08/26 18:26:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 430/1798]  lr: 8.5986e-05  eta: 0:09:55  time: 0.4127  data_time: 0.0030  memory: 5210  loss: 1.7831  loss_cls: 1.1277  loss_bbox: 0.6553\n",
      "08/26 18:26:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 440/1798]  lr: 8.7988e-05  eta: 0:09:50  time: 0.4096  data_time: 0.0029  memory: 5210  loss: 1.7861  loss_cls: 1.1274  loss_bbox: 0.6587\n",
      "08/26 18:26:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 450/1798]  lr: 8.9990e-05  eta: 0:09:45  time: 0.4074  data_time: 0.0029  memory: 5210  loss: 1.7849  loss_cls: 1.1269  loss_bbox: 0.6580\n",
      "08/26 18:26:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 460/1798]  lr: 9.1992e-05  eta: 0:09:40  time: 0.4066  data_time: 0.0028  memory: 5210  loss: 1.7726  loss_cls: 1.1263  loss_bbox: 0.6463\n",
      "08/26 18:26:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 470/1798]  lr: 9.3994e-05  eta: 0:09:34  time: 0.4068  data_time: 0.0029  memory: 5210  loss: 1.7707  loss_cls: 1.1258  loss_bbox: 0.6450\n",
      "08/26 18:27:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 480/1798]  lr: 9.5996e-05  eta: 0:09:29  time: 0.4070  data_time: 0.0027  memory: 5210  loss: 1.7662  loss_cls: 1.1251  loss_bbox: 0.6411\n",
      "08/26 18:27:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 490/1798]  lr: 9.7998e-05  eta: 0:09:24  time: 0.4066  data_time: 0.0027  memory: 5210  loss: 1.7629  loss_cls: 1.1251  loss_bbox: 0.6377\n",
      "08/26 18:27:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 500/1798]  lr: 1.0000e-04  eta: 0:09:19  time: 0.4063  data_time: 0.0027  memory: 5210  loss: 1.7592  loss_cls: 1.1248  loss_bbox: 0.6344\n",
      "08/26 18:27:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 510/1798]  lr: 1.0000e-04  eta: 0:09:14  time: 0.4060  data_time: 0.0028  memory: 5210  loss: 1.7598  loss_cls: 1.1247  loss_bbox: 0.6351\n",
      "08/26 18:27:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 520/1798]  lr: 1.0000e-04  eta: 0:09:10  time: 0.4064  data_time: 0.0028  memory: 5210  loss: 1.7592  loss_cls: 1.1244  loss_bbox: 0.6348\n",
      "08/26 18:27:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 530/1798]  lr: 1.0000e-04  eta: 0:09:05  time: 0.4060  data_time: 0.0028  memory: 5210  loss: 1.7618  loss_cls: 1.1242  loss_bbox: 0.6377\n",
      "08/26 18:27:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 540/1798]  lr: 1.0000e-04  eta: 0:09:00  time: 0.4059  data_time: 0.0027  memory: 5210  loss: 1.7588  loss_cls: 1.1237  loss_bbox: 0.6350\n",
      "08/26 18:27:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 550/1798]  lr: 1.0000e-04  eta: 0:08:55  time: 0.4058  data_time: 0.0027  memory: 5210  loss: 1.7593  loss_cls: 1.1237  loss_bbox: 0.6355\n",
      "08/26 18:27:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 560/1798]  lr: 1.0000e-04  eta: 0:08:50  time: 0.4056  data_time: 0.0026  memory: 5210  loss: 1.7597  loss_cls: 1.1234  loss_bbox: 0.6363\n",
      "08/26 18:27:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 570/1798]  lr: 1.0000e-04  eta: 0:08:45  time: 0.4049  data_time: 0.0027  memory: 5210  loss: 1.7605  loss_cls: 1.1234  loss_bbox: 0.6371\n",
      "08/26 18:27:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 580/1798]  lr: 1.0000e-04  eta: 0:08:41  time: 0.4050  data_time: 0.0027  memory: 5210  loss: 1.7588  loss_cls: 1.1231  loss_bbox: 0.6357\n",
      "08/26 18:27:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 590/1798]  lr: 1.0000e-04  eta: 0:08:36  time: 0.4052  data_time: 0.0028  memory: 5210  loss: 1.7654  loss_cls: 1.1230  loss_bbox: 0.6424\n",
      "08/26 18:27:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 600/1798]  lr: 1.0000e-04  eta: 0:08:31  time: 0.4053  data_time: 0.0028  memory: 5210  loss: 1.7668  loss_cls: 1.1226  loss_bbox: 0.6442\n",
      "08/26 18:27:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 610/1798]  lr: 1.0000e-04  eta: 0:08:26  time: 0.4057  data_time: 0.0028  memory: 5210  loss: 1.7663  loss_cls: 1.1221  loss_bbox: 0.6441\n",
      "08/26 18:27:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 620/1798]  lr: 1.0000e-04  eta: 0:08:22  time: 0.4061  data_time: 0.0029  memory: 5210  loss: 1.7626  loss_cls: 1.1213  loss_bbox: 0.6413\n",
      "08/26 18:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 630/1798]  lr: 1.0000e-04  eta: 0:08:17  time: 0.4060  data_time: 0.0028  memory: 5210  loss: 1.7624  loss_cls: 1.1213  loss_bbox: 0.6412\n",
      "08/26 18:28:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 640/1798]  lr: 1.0000e-04  eta: 0:08:12  time: 0.4059  data_time: 0.0028  memory: 5210  loss: 1.7568  loss_cls: 1.1205  loss_bbox: 0.6363\n",
      "08/26 18:28:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 650/1798]  lr: 1.0000e-04  eta: 0:08:08  time: 0.4060  data_time: 0.0028  memory: 5210  loss: 1.7535  loss_cls: 1.1199  loss_bbox: 0.6335\n",
      "08/26 18:28:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 660/1798]  lr: 1.0000e-04  eta: 0:08:03  time: 0.4060  data_time: 0.0028  memory: 5210  loss: 1.7578  loss_cls: 1.1199  loss_bbox: 0.6379\n",
      "08/26 18:28:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 670/1798]  lr: 1.0000e-04  eta: 0:07:59  time: 0.4059  data_time: 0.0028  memory: 5210  loss: 1.7576  loss_cls: 1.1198  loss_bbox: 0.6378\n",
      "08/26 18:28:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 680/1798]  lr: 1.0000e-04  eta: 0:07:54  time: 0.4083  data_time: 0.0029  memory: 5210  loss: 1.7558  loss_cls: 1.1190  loss_bbox: 0.6368\n",
      "08/26 18:28:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 690/1798]  lr: 1.0000e-04  eta: 0:07:50  time: 0.4081  data_time: 0.0028  memory: 5210  loss: 1.7558  loss_cls: 1.1186  loss_bbox: 0.6373\n",
      "08/26 18:28:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 700/1798]  lr: 1.0000e-04  eta: 0:07:45  time: 0.4082  data_time: 0.0027  memory: 5210  loss: 1.7565  loss_cls: 1.1184  loss_bbox: 0.6381\n",
      "08/26 18:28:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 710/1798]  lr: 1.0000e-04  eta: 0:07:41  time: 0.4082  data_time: 0.0027  memory: 5210  loss: 1.7482  loss_cls: 1.1177  loss_bbox: 0.6305\n",
      "08/26 18:28:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 720/1798]  lr: 1.0000e-04  eta: 0:07:36  time: 0.4087  data_time: 0.0027  memory: 5210  loss: 1.7516  loss_cls: 1.1173  loss_bbox: 0.6344\n",
      "08/26 18:28:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 730/1798]  lr: 1.0000e-04  eta: 0:07:32  time: 0.4064  data_time: 0.0027  memory: 5210  loss: 1.7505  loss_cls: 1.1168  loss_bbox: 0.6338\n",
      "08/26 18:28:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 740/1798]  lr: 1.0000e-04  eta: 0:07:27  time: 0.4068  data_time: 0.0027  memory: 5210  loss: 1.7460  loss_cls: 1.1162  loss_bbox: 0.6298\n",
      "08/26 18:28:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 750/1798]  lr: 1.0000e-04  eta: 0:07:23  time: 0.4074  data_time: 0.0027  memory: 5210  loss: 1.7427  loss_cls: 1.1157  loss_bbox: 0.6270\n",
      "08/26 18:28:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 760/1798]  lr: 1.0000e-04  eta: 0:07:18  time: 0.4073  data_time: 0.0027  memory: 5210  loss: 1.7401  loss_cls: 1.1148  loss_bbox: 0.6253\n",
      "08/26 18:28:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 770/1798]  lr: 1.0000e-04  eta: 0:07:14  time: 0.4073  data_time: 0.0027  memory: 5210  loss: 1.7356  loss_cls: 1.1135  loss_bbox: 0.6222\n",
      "08/26 18:29:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 780/1798]  lr: 1.0000e-04  eta: 0:07:10  time: 0.4072  data_time: 0.0027  memory: 5210  loss: 1.7350  loss_cls: 1.1125  loss_bbox: 0.6224\n",
      "08/26 18:29:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 790/1798]  lr: 1.0000e-04  eta: 0:07:05  time: 0.4068  data_time: 0.0027  memory: 5210  loss: 1.7379  loss_cls: 1.1116  loss_bbox: 0.6262\n",
      "08/26 18:29:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 800/1798]  lr: 1.0000e-04  eta: 0:07:01  time: 0.4063  data_time: 0.0027  memory: 5210  loss: 1.7380  loss_cls: 1.1108  loss_bbox: 0.6272\n",
      "08/26 18:29:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 810/1798]  lr: 1.0000e-04  eta: 0:06:56  time: 0.4063  data_time: 0.0027  memory: 5210  loss: 1.7385  loss_cls: 1.1104  loss_bbox: 0.6281\n",
      "08/26 18:29:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 820/1798]  lr: 1.0000e-04  eta: 0:06:52  time: 0.4062  data_time: 0.0027  memory: 5210  loss: 1.7393  loss_cls: 1.1096  loss_bbox: 0.6297\n",
      "08/26 18:29:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 830/1798]  lr: 1.0000e-04  eta: 0:06:48  time: 0.4067  data_time: 0.0027  memory: 5210  loss: 1.7378  loss_cls: 1.1089  loss_bbox: 0.6289\n",
      "08/26 18:29:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 840/1798]  lr: 1.0000e-04  eta: 0:06:43  time: 0.4071  data_time: 0.0027  memory: 5210  loss: 1.7351  loss_cls: 1.1084  loss_bbox: 0.6268\n",
      "08/26 18:29:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 850/1798]  lr: 1.0000e-04  eta: 0:06:39  time: 0.4085  data_time: 0.0026  memory: 5210  loss: 1.7366  loss_cls: 1.1073  loss_bbox: 0.6292\n",
      "08/26 18:29:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 860/1798]  lr: 1.0000e-04  eta: 0:06:35  time: 0.4107  data_time: 0.0027  memory: 5210  loss: 1.7345  loss_cls: 1.1058  loss_bbox: 0.6286\n",
      "08/26 18:29:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 870/1798]  lr: 1.0000e-04  eta: 0:06:30  time: 0.4129  data_time: 0.0028  memory: 5210  loss: 1.7284  loss_cls: 1.1049  loss_bbox: 0.6235\n",
      "08/26 18:29:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 880/1798]  lr: 1.0000e-04  eta: 0:06:26  time: 0.4128  data_time: 0.0028  memory: 5210  loss: 1.7257  loss_cls: 1.1033  loss_bbox: 0.6224\n",
      "08/26 18:29:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 890/1798]  lr: 1.0000e-04  eta: 0:06:22  time: 0.4132  data_time: 0.0029  memory: 5210  loss: 1.7225  loss_cls: 1.1019  loss_bbox: 0.6206\n",
      "08/26 18:29:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 900/1798]  lr: 1.0000e-04  eta: 0:06:17  time: 0.4123  data_time: 0.0030  memory: 5210  loss: 1.7181  loss_cls: 1.1000  loss_bbox: 0.6180\n",
      "08/26 18:29:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 910/1798]  lr: 1.0000e-04  eta: 0:06:13  time: 0.4101  data_time: 0.0030  memory: 5210  loss: 1.7172  loss_cls: 1.0982  loss_bbox: 0.6190\n",
      "08/26 18:30:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 920/1798]  lr: 1.0000e-04  eta: 0:06:09  time: 0.4082  data_time: 0.0030  memory: 5210  loss: 1.7205  loss_cls: 1.0967  loss_bbox: 0.6238\n",
      "08/26 18:30:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 930/1798]  lr: 1.0000e-04  eta: 0:06:04  time: 0.4083  data_time: 0.0031  memory: 5210  loss: 1.7215  loss_cls: 1.0943  loss_bbox: 0.6273\n",
      "08/26 18:30:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 940/1798]  lr: 1.0000e-04  eta: 0:06:00  time: 0.4079  data_time: 0.0031  memory: 5210  loss: 1.7206  loss_cls: 1.0921  loss_bbox: 0.6285\n",
      "08/26 18:30:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 950/1798]  lr: 1.0000e-04  eta: 0:05:56  time: 0.4073  data_time: 0.0030  memory: 5210  loss: 1.7158  loss_cls: 1.0894  loss_bbox: 0.6265\n",
      "08/26 18:30:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 960/1798]  lr: 1.0000e-04  eta: 0:05:51  time: 0.4072  data_time: 0.0030  memory: 5210  loss: 1.7170  loss_cls: 1.0881  loss_bbox: 0.6290\n",
      "08/26 18:30:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 970/1798]  lr: 1.0000e-04  eta: 0:05:47  time: 0.4072  data_time: 0.0031  memory: 5210  loss: 1.7144  loss_cls: 1.0850  loss_bbox: 0.6294\n",
      "08/26 18:30:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 980/1798]  lr: 1.0000e-04  eta: 0:05:43  time: 0.4068  data_time: 0.0030  memory: 5210  loss: 1.7069  loss_cls: 1.0816  loss_bbox: 0.6253\n",
      "08/26 18:30:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 990/1798]  lr: 1.0000e-04  eta: 0:05:38  time: 0.4070  data_time: 0.0029  memory: 5210  loss: 1.7014  loss_cls: 1.0777  loss_bbox: 0.6237\n",
      "08/26 18:30:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: retinanet_swin-t-p4-w7_fpn_1x_coco_20250826_182323\n",
      "08/26 18:30:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1000/1798]  lr: 1.0000e-04  eta: 0:05:34  time: 0.4073  data_time: 0.0030  memory: 5210  loss: 1.6988  loss_cls: 1.0744  loss_bbox: 0.6244\n",
      "08/26 18:30:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1010/1798]  lr: 1.0000e-04  eta: 0:05:30  time: 0.4076  data_time: 0.0029  memory: 5210  loss: 1.6927  loss_cls: 1.0694  loss_bbox: 0.6233\n",
      "08/26 18:30:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1020/1798]  lr: 1.0000e-04  eta: 0:05:26  time: 0.4078  data_time: 0.0029  memory: 5210  loss: 1.6820  loss_cls: 1.0630  loss_bbox: 0.6190\n",
      "08/26 18:30:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1030/1798]  lr: 1.0000e-04  eta: 0:05:21  time: 0.4077  data_time: 0.0029  memory: 5210  loss: 1.6748  loss_cls: 1.0580  loss_bbox: 0.6168\n",
      "08/26 18:30:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1040/1798]  lr: 1.0000e-04  eta: 0:05:17  time: 0.4079  data_time: 0.0029  memory: 5210  loss: 1.6742  loss_cls: 1.0531  loss_bbox: 0.6211\n",
      "08/26 18:30:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1050/1798]  lr: 1.0000e-04  eta: 0:05:13  time: 0.4081  data_time: 0.0029  memory: 5210  loss: 1.6647  loss_cls: 1.0412  loss_bbox: 0.6235\n",
      "08/26 18:30:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1060/1798]  lr: 1.0000e-04  eta: 0:05:09  time: 0.4077  data_time: 0.0029  memory: 5210  loss: 1.6509  loss_cls: 1.0317  loss_bbox: 0.6192\n",
      "08/26 18:31:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1070/1798]  lr: 1.0000e-04  eta: 0:05:04  time: 0.4078  data_time: 0.0029  memory: 5210  loss: 1.6416  loss_cls: 1.0177  loss_bbox: 0.6239\n",
      "08/26 18:31:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1080/1798]  lr: 1.0000e-04  eta: 0:05:00  time: 0.4078  data_time: 0.0028  memory: 5210  loss: 1.6416  loss_cls: 1.0107  loss_bbox: 0.6309\n",
      "08/26 18:31:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1090/1798]  lr: 1.0000e-04  eta: 0:04:56  time: 0.4073  data_time: 0.0028  memory: 5210  loss: 1.6254  loss_cls: 0.9931  loss_bbox: 0.6322\n",
      "08/26 18:31:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1100/1798]  lr: 1.0000e-04  eta: 0:04:51  time: 0.4072  data_time: 0.0029  memory: 5210  loss: 1.6127  loss_cls: 0.9822  loss_bbox: 0.6306\n",
      "08/26 18:31:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1110/1798]  lr: 1.0000e-04  eta: 0:04:47  time: 0.4075  data_time: 0.0029  memory: 5210  loss: 1.6018  loss_cls: 0.9701  loss_bbox: 0.6317\n",
      "08/26 18:31:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1120/1798]  lr: 1.0000e-04  eta: 0:04:43  time: 0.4075  data_time: 0.0029  memory: 5210  loss: 1.5858  loss_cls: 0.9580  loss_bbox: 0.6278\n",
      "08/26 18:31:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1130/1798]  lr: 1.0000e-04  eta: 0:04:39  time: 0.4077  data_time: 0.0030  memory: 5210  loss: 1.5681  loss_cls: 0.9458  loss_bbox: 0.6223\n",
      "08/26 18:31:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1140/1798]  lr: 1.0000e-04  eta: 0:04:35  time: 0.4078  data_time: 0.0030  memory: 5210  loss: 1.5561  loss_cls: 0.9390  loss_bbox: 0.6171\n",
      "08/26 18:31:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1150/1798]  lr: 1.0000e-04  eta: 0:04:30  time: 0.4083  data_time: 0.0030  memory: 5210  loss: 1.5508  loss_cls: 0.9322  loss_bbox: 0.6186\n",
      "08/26 18:31:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1160/1798]  lr: 1.0000e-04  eta: 0:04:26  time: 0.4090  data_time: 0.0029  memory: 5210  loss: 1.5376  loss_cls: 0.9167  loss_bbox: 0.6209\n",
      "08/26 18:31:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1170/1798]  lr: 1.0000e-04  eta: 0:04:22  time: 0.4117  data_time: 0.0030  memory: 5210  loss: 1.5365  loss_cls: 0.9148  loss_bbox: 0.6217\n",
      "08/26 18:31:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1180/1798]  lr: 1.0000e-04  eta: 0:04:18  time: 0.4114  data_time: 0.0030  memory: 5210  loss: 1.5317  loss_cls: 0.9100  loss_bbox: 0.6217\n",
      "08/26 18:31:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1190/1798]  lr: 1.0000e-04  eta: 0:04:13  time: 0.4112  data_time: 0.0030  memory: 5210  loss: 1.5267  loss_cls: 0.9057  loss_bbox: 0.6210\n",
      "08/26 18:31:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1200/1798]  lr: 1.0000e-04  eta: 0:04:09  time: 0.4106  data_time: 0.0031  memory: 5210  loss: 1.5117  loss_cls: 0.8966  loss_bbox: 0.6151\n",
      "08/26 18:31:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1210/1798]  lr: 1.0000e-04  eta: 0:04:05  time: 0.4093  data_time: 0.0030  memory: 5210  loss: 1.5112  loss_cls: 0.8968  loss_bbox: 0.6144\n",
      "08/26 18:32:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1220/1798]  lr: 1.0000e-04  eta: 0:04:01  time: 0.4060  data_time: 0.0029  memory: 5210  loss: 1.5084  loss_cls: 0.8943  loss_bbox: 0.6141\n",
      "08/26 18:32:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1230/1798]  lr: 1.0000e-04  eta: 0:03:57  time: 0.4060  data_time: 0.0029  memory: 5210  loss: 1.5062  loss_cls: 0.8869  loss_bbox: 0.6193\n",
      "08/26 18:32:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1240/1798]  lr: 1.0000e-04  eta: 0:03:52  time: 0.4068  data_time: 0.0031  memory: 5210  loss: 1.4955  loss_cls: 0.8754  loss_bbox: 0.6200\n",
      "08/26 18:32:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1250/1798]  lr: 1.0000e-04  eta: 0:03:48  time: 0.4064  data_time: 0.0030  memory: 5210  loss: 1.5105  loss_cls: 0.8718  loss_bbox: 0.6387\n",
      "08/26 18:32:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1260/1798]  lr: 1.0000e-04  eta: 0:03:44  time: 0.4069  data_time: 0.0031  memory: 5210  loss: 1.4985  loss_cls: 0.8646  loss_bbox: 0.6339\n",
      "08/26 18:32:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1270/1798]  lr: 1.0000e-04  eta: 0:03:40  time: 0.4070  data_time: 0.0032  memory: 5210  loss: 1.4791  loss_cls: 0.8465  loss_bbox: 0.6326\n",
      "08/26 18:32:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1280/1798]  lr: 1.0000e-04  eta: 0:03:35  time: 0.4071  data_time: 0.0031  memory: 5210  loss: 1.4636  loss_cls: 0.8342  loss_bbox: 0.6293\n",
      "08/26 18:32:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1290/1798]  lr: 1.0000e-04  eta: 0:03:31  time: 0.4069  data_time: 0.0030  memory: 5210  loss: 1.4560  loss_cls: 0.8245  loss_bbox: 0.6315\n",
      "08/26 18:32:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1300/1798]  lr: 1.0000e-04  eta: 0:03:27  time: 0.4073  data_time: 0.0030  memory: 5210  loss: 1.4308  loss_cls: 0.8119  loss_bbox: 0.6189\n",
      "08/26 18:32:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1310/1798]  lr: 1.0000e-04  eta: 0:03:23  time: 0.4072  data_time: 0.0030  memory: 5210  loss: 1.4298  loss_cls: 0.8041  loss_bbox: 0.6257\n",
      "08/26 18:32:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1320/1798]  lr: 1.0000e-04  eta: 0:03:19  time: 0.4078  data_time: 0.0031  memory: 5210  loss: 1.4224  loss_cls: 0.7985  loss_bbox: 0.6240\n",
      "08/26 18:32:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1330/1798]  lr: 1.0000e-04  eta: 0:03:14  time: 0.4080  data_time: 0.0030  memory: 5210  loss: 1.4126  loss_cls: 0.7899  loss_bbox: 0.6227\n",
      "08/26 18:32:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1340/1798]  lr: 1.0000e-04  eta: 0:03:10  time: 0.4079  data_time: 0.0030  memory: 5210  loss: 1.4027  loss_cls: 0.7819  loss_bbox: 0.6208\n",
      "08/26 18:32:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1350/1798]  lr: 1.0000e-04  eta: 0:03:06  time: 0.4077  data_time: 0.0030  memory: 5210  loss: 1.4006  loss_cls: 0.7813  loss_bbox: 0.6193\n",
      "08/26 18:33:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1360/1798]  lr: 1.0000e-04  eta: 0:03:02  time: 0.4077  data_time: 0.0030  memory: 5210  loss: 1.3874  loss_cls: 0.7704  loss_bbox: 0.6170\n",
      "08/26 18:33:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1370/1798]  lr: 1.0000e-04  eta: 0:02:58  time: 0.4071  data_time: 0.0029  memory: 5210  loss: 1.3879  loss_cls: 0.7693  loss_bbox: 0.6186\n",
      "08/26 18:33:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1380/1798]  lr: 1.0000e-04  eta: 0:02:53  time: 0.4068  data_time: 0.0030  memory: 5210  loss: 1.3734  loss_cls: 0.7583  loss_bbox: 0.6151\n",
      "08/26 18:33:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1390/1798]  lr: 1.0000e-04  eta: 0:02:49  time: 0.4068  data_time: 0.0030  memory: 5210  loss: 1.3769  loss_cls: 0.7618  loss_bbox: 0.6151\n",
      "08/26 18:33:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1400/1798]  lr: 1.0000e-04  eta: 0:02:45  time: 0.4072  data_time: 0.0030  memory: 5210  loss: 1.3651  loss_cls: 0.7538  loss_bbox: 0.6113\n",
      "08/26 18:33:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1410/1798]  lr: 1.0000e-04  eta: 0:02:41  time: 0.4069  data_time: 0.0029  memory: 5210  loss: 1.3649  loss_cls: 0.7526  loss_bbox: 0.6124\n",
      "08/26 18:33:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1420/1798]  lr: 1.0000e-04  eta: 0:02:37  time: 0.4068  data_time: 0.0029  memory: 5210  loss: 1.3538  loss_cls: 0.7439  loss_bbox: 0.6099\n",
      "08/26 18:33:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1430/1798]  lr: 1.0000e-04  eta: 0:02:33  time: 0.4074  data_time: 0.0029  memory: 5210  loss: 1.3439  loss_cls: 0.7346  loss_bbox: 0.6093\n",
      "08/26 18:33:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1440/1798]  lr: 1.0000e-04  eta: 0:02:28  time: 0.4075  data_time: 0.0029  memory: 5210  loss: 1.3312  loss_cls: 0.7201  loss_bbox: 0.6110\n",
      "08/26 18:33:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1450/1798]  lr: 1.0000e-04  eta: 0:02:24  time: 0.4071  data_time: 0.0029  memory: 5210  loss: 1.3338  loss_cls: 0.7176  loss_bbox: 0.6163\n",
      "08/26 18:33:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1460/1798]  lr: 1.0000e-04  eta: 0:02:20  time: 0.4072  data_time: 0.0029  memory: 5210  loss: 1.3251  loss_cls: 0.7128  loss_bbox: 0.6123\n",
      "08/26 18:33:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1470/1798]  lr: 1.0000e-04  eta: 0:02:16  time: 0.4075  data_time: 0.0029  memory: 5210  loss: 1.3235  loss_cls: 0.7057  loss_bbox: 0.6178\n",
      "08/26 18:33:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1480/1798]  lr: 1.0000e-04  eta: 0:02:12  time: 0.4077  data_time: 0.0029  memory: 5210  loss: 1.3208  loss_cls: 0.7017  loss_bbox: 0.6191\n",
      "08/26 18:33:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1490/1798]  lr: 1.0000e-04  eta: 0:02:07  time: 0.4079  data_time: 0.0029  memory: 5210  loss: 1.3134  loss_cls: 0.6948  loss_bbox: 0.6186\n",
      "08/26 18:33:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1500/1798]  lr: 1.0000e-04  eta: 0:02:03  time: 0.4093  data_time: 0.0030  memory: 5210  loss: 1.3065  loss_cls: 0.6930  loss_bbox: 0.6135\n",
      "08/26 18:34:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1510/1798]  lr: 1.0000e-04  eta: 0:01:59  time: 0.4093  data_time: 0.0030  memory: 5210  loss: 1.3071  loss_cls: 0.6925  loss_bbox: 0.6146\n",
      "08/26 18:34:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1520/1798]  lr: 1.0000e-04  eta: 0:01:55  time: 0.4091  data_time: 0.0029  memory: 5210  loss: 1.3016  loss_cls: 0.6907  loss_bbox: 0.6109\n",
      "08/26 18:34:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1530/1798]  lr: 1.0000e-04  eta: 0:01:51  time: 0.4090  data_time: 0.0029  memory: 5210  loss: 1.2974  loss_cls: 0.6873  loss_bbox: 0.6101\n",
      "08/26 18:34:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1540/1798]  lr: 1.0000e-04  eta: 0:01:47  time: 0.4086  data_time: 0.0029  memory: 5210  loss: 1.3044  loss_cls: 0.6929  loss_bbox: 0.6114\n",
      "08/26 18:34:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1550/1798]  lr: 1.0000e-04  eta: 0:01:42  time: 0.4075  data_time: 0.0028  memory: 5210  loss: 1.3007  loss_cls: 0.6830  loss_bbox: 0.6177\n",
      "08/26 18:34:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1560/1798]  lr: 1.0000e-04  eta: 0:01:38  time: 0.4076  data_time: 0.0029  memory: 5210  loss: 1.2932  loss_cls: 0.6723  loss_bbox: 0.6208\n",
      "08/26 18:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1570/1798]  lr: 1.0000e-04  eta: 0:01:34  time: 0.4075  data_time: 0.0029  memory: 5210  loss: 1.2866  loss_cls: 0.6660  loss_bbox: 0.6207\n",
      "08/26 18:34:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1580/1798]  lr: 1.0000e-04  eta: 0:01:30  time: 0.4071  data_time: 0.0029  memory: 5210  loss: 1.2853  loss_cls: 0.6581  loss_bbox: 0.6272\n",
      "08/26 18:34:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1590/1798]  lr: 1.0000e-04  eta: 0:01:26  time: 0.4071  data_time: 0.0029  memory: 5210  loss: 1.2692  loss_cls: 0.6455  loss_bbox: 0.6237\n",
      "08/26 18:34:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1600/1798]  lr: 1.0000e-04  eta: 0:01:22  time: 0.4067  data_time: 0.0029  memory: 5210  loss: 1.2596  loss_cls: 0.6370  loss_bbox: 0.6227\n",
      "08/26 18:34:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1610/1798]  lr: 1.0000e-04  eta: 0:01:18  time: 0.4065  data_time: 0.0029  memory: 5210  loss: 1.2488  loss_cls: 0.6288  loss_bbox: 0.6201\n",
      "08/26 18:34:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1620/1798]  lr: 1.0000e-04  eta: 0:01:13  time: 0.4065  data_time: 0.0029  memory: 5210  loss: 1.2441  loss_cls: 0.6231  loss_bbox: 0.6209\n",
      "08/26 18:34:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1630/1798]  lr: 1.0000e-04  eta: 0:01:09  time: 0.4065  data_time: 0.0029  memory: 5210  loss: 1.2423  loss_cls: 0.6265  loss_bbox: 0.6158\n",
      "08/26 18:34:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1640/1798]  lr: 1.0000e-04  eta: 0:01:05  time: 0.4067  data_time: 0.0030  memory: 5210  loss: 1.2382  loss_cls: 0.6220  loss_bbox: 0.6162\n",
      "08/26 18:34:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1650/1798]  lr: 1.0000e-04  eta: 0:01:01  time: 0.4070  data_time: 0.0030  memory: 5210  loss: 1.2192  loss_cls: 0.6082  loss_bbox: 0.6110\n",
      "08/26 18:35:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1660/1798]  lr: 1.0000e-04  eta: 0:00:57  time: 0.4069  data_time: 0.0030  memory: 5210  loss: 1.2212  loss_cls: 0.6084  loss_bbox: 0.6128\n",
      "08/26 18:35:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1670/1798]  lr: 1.0000e-04  eta: 0:00:53  time: 0.4068  data_time: 0.0029  memory: 5210  loss: 1.2282  loss_cls: 0.6141  loss_bbox: 0.6141\n",
      "08/26 18:35:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1680/1798]  lr: 1.0000e-04  eta: 0:00:48  time: 0.4069  data_time: 0.0029  memory: 5210  loss: 1.2308  loss_cls: 0.6081  loss_bbox: 0.6226\n",
      "08/26 18:35:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1690/1798]  lr: 1.0000e-04  eta: 0:00:44  time: 0.4066  data_time: 0.0028  memory: 5210  loss: 1.2276  loss_cls: 0.6103  loss_bbox: 0.6173\n",
      "08/26 18:35:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1700/1798]  lr: 1.0000e-04  eta: 0:00:40  time: 0.4065  data_time: 0.0029  memory: 5210  loss: 1.2337  loss_cls: 0.6176  loss_bbox: 0.6161\n",
      "08/26 18:35:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1710/1798]  lr: 1.0000e-04  eta: 0:00:36  time: 0.4064  data_time: 0.0028  memory: 5210  loss: 1.2251  loss_cls: 0.6080  loss_bbox: 0.6171\n",
      "08/26 18:35:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1720/1798]  lr: 1.0000e-04  eta: 0:00:32  time: 0.4064  data_time: 0.0028  memory: 5210  loss: 1.2111  loss_cls: 0.5967  loss_bbox: 0.6144\n",
      "08/26 18:35:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1730/1798]  lr: 1.0000e-04  eta: 0:00:28  time: 0.4063  data_time: 0.0028  memory: 5210  loss: 1.2149  loss_cls: 0.6043  loss_bbox: 0.6106\n",
      "08/26 18:35:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1740/1798]  lr: 1.0000e-04  eta: 0:00:24  time: 0.4064  data_time: 0.0029  memory: 5210  loss: 1.2060  loss_cls: 0.5884  loss_bbox: 0.6175\n",
      "08/26 18:35:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1750/1798]  lr: 1.0000e-04  eta: 0:00:19  time: 0.4064  data_time: 0.0028  memory: 5210  loss: 1.2055  loss_cls: 0.5847  loss_bbox: 0.6207\n",
      "08/26 18:35:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1760/1798]  lr: 1.0000e-04  eta: 0:00:15  time: 0.4067  data_time: 0.0030  memory: 5210  loss: 1.2080  loss_cls: 0.5884  loss_bbox: 0.6196\n",
      "08/26 18:35:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1770/1798]  lr: 1.0000e-04  eta: 0:00:11  time: 0.4068  data_time: 0.0030  memory: 5210  loss: 1.2088  loss_cls: 0.5881  loss_bbox: 0.6207\n",
      "08/26 18:35:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1780/1798]  lr: 1.0000e-04  eta: 0:00:07  time: 0.4068  data_time: 0.0030  memory: 5210  loss: 1.1996  loss_cls: 0.5838  loss_bbox: 0.6158\n",
      "08/26 18:35:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][1790/1798]  lr: 1.0000e-04  eta: 0:00:03  time: 0.4067  data_time: 0.0030  memory: 5210  loss: 1.2046  loss_cls: 0.5911  loss_bbox: 0.6136\n",
      "08/26 18:35:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: retinanet_swin-t-p4-w7_fpn_1x_coco_20250826_182323\n",
      "08/26 18:35:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "08/26 18:36:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][ 10/909]    eta: 0:15:01  time: 1.0029  data_time: 0.9088  memory: 5210  \n",
      "08/26 18:36:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][ 20/909]    eta: 0:08:02  time: 0.5425  data_time: 0.4553  memory: 663  \n",
      "08/26 18:36:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][ 30/909]    eta: 0:05:42  time: 0.3894  data_time: 0.3041  memory: 663  \n",
      "08/26 18:36:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][ 40/909]    eta: 0:04:31  time: 0.3122  data_time: 0.2284  memory: 663  \n",
      "08/26 18:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][ 50/909]    eta: 0:03:48  time: 0.2655  data_time: 0.1830  memory: 663  \n",
      "08/26 18:36:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][ 60/909]    eta: 0:03:19  time: 0.0808  data_time: 0.0015  memory: 663  \n",
      "08/26 18:36:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][ 70/909]    eta: 0:02:58  time: 0.0801  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][ 80/909]    eta: 0:02:42  time: 0.0792  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][ 90/909]    eta: 0:02:29  time: 0.0789  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][100/909]    eta: 0:02:19  time: 0.0789  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][110/909]    eta: 0:02:10  time: 0.0789  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][120/909]    eta: 0:02:03  time: 0.0789  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][130/909]    eta: 0:01:57  time: 0.0785  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][140/909]    eta: 0:01:51  time: 0.0784  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][150/909]    eta: 0:01:46  time: 0.0782  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][160/909]    eta: 0:01:42  time: 0.0780  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][170/909]    eta: 0:01:38  time: 0.0775  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][180/909]    eta: 0:01:34  time: 0.0774  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][190/909]    eta: 0:01:31  time: 0.0773  data_time: 0.0012  memory: 663  \n",
      "08/26 18:36:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][200/909]    eta: 0:01:28  time: 0.0771  data_time: 0.0012  memory: 663  \n",
      "08/26 18:36:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][210/909]    eta: 0:01:25  time: 0.0769  data_time: 0.0012  memory: 663  \n",
      "08/26 18:36:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][220/909]    eta: 0:01:23  time: 0.0771  data_time: 0.0012  memory: 663  \n",
      "08/26 18:36:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][230/909]    eta: 0:01:20  time: 0.0771  data_time: 0.0012  memory: 663  \n",
      "08/26 18:36:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][240/909]    eta: 0:01:18  time: 0.0769  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][250/909]    eta: 0:01:15  time: 0.0769  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][260/909]    eta: 0:01:13  time: 0.0771  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][270/909]    eta: 0:01:11  time: 0.0769  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][280/909]    eta: 0:01:09  time: 0.0771  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][290/909]    eta: 0:01:08  time: 0.0773  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][300/909]    eta: 0:01:06  time: 0.0773  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][310/909]    eta: 0:01:04  time: 0.0770  data_time: 0.0012  memory: 663  \n",
      "08/26 18:36:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][320/909]    eta: 0:01:02  time: 0.0771  data_time: 0.0012  memory: 663  \n",
      "08/26 18:36:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][330/909]    eta: 0:01:01  time: 0.0770  data_time: 0.0012  memory: 663  \n",
      "08/26 18:36:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][340/909]    eta: 0:00:59  time: 0.0767  data_time: 0.0012  memory: 663  \n",
      "08/26 18:36:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][350/909]    eta: 0:00:58  time: 0.0766  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][360/909]    eta: 0:00:56  time: 0.0767  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][370/909]    eta: 0:00:55  time: 0.0765  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][380/909]    eta: 0:00:54  time: 0.0768  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][390/909]    eta: 0:00:52  time: 0.0771  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][400/909]    eta: 0:00:51  time: 0.0771  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][410/909]    eta: 0:00:50  time: 0.0772  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][420/909]    eta: 0:00:48  time: 0.0775  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][430/909]    eta: 0:00:47  time: 0.0773  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][440/909]    eta: 0:00:46  time: 0.0769  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][450/909]    eta: 0:00:45  time: 0.0770  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][460/909]    eta: 0:00:43  time: 0.0771  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][470/909]    eta: 0:00:42  time: 0.0770  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][480/909]    eta: 0:00:41  time: 0.0770  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][490/909]    eta: 0:00:40  time: 0.0772  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][500/909]    eta: 0:00:39  time: 0.0772  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][510/909]    eta: 0:00:38  time: 0.0771  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][520/909]    eta: 0:00:37  time: 0.0770  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][530/909]    eta: 0:00:36  time: 0.0768  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][540/909]    eta: 0:00:34  time: 0.0769  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][550/909]    eta: 0:00:33  time: 0.0770  data_time: 0.0013  memory: 663  \n",
      "08/26 18:36:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][560/909]    eta: 0:00:32  time: 0.0771  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][570/909]    eta: 0:00:31  time: 0.0770  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][580/909]    eta: 0:00:30  time: 0.0772  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][590/909]    eta: 0:00:29  time: 0.0773  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][600/909]    eta: 0:00:28  time: 0.0770  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][610/909]    eta: 0:00:27  time: 0.0771  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][620/909]    eta: 0:00:26  time: 0.0770  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][630/909]    eta: 0:00:25  time: 0.0769  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][640/909]    eta: 0:00:24  time: 0.0776  data_time: 0.0014  memory: 663  \n",
      "08/26 18:36:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][650/909]    eta: 0:00:23  time: 0.0776  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][660/909]    eta: 0:00:22  time: 0.0776  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][670/909]    eta: 0:00:21  time: 0.0777  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][680/909]    eta: 0:00:20  time: 0.0778  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][690/909]    eta: 0:00:19  time: 0.0769  data_time: 0.0013  memory: 663  \n",
      "08/26 18:37:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][700/909]    eta: 0:00:18  time: 0.0769  data_time: 0.0013  memory: 663  \n",
      "08/26 18:37:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][710/909]    eta: 0:00:18  time: 0.0767  data_time: 0.0013  memory: 663  \n",
      "08/26 18:37:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][720/909]    eta: 0:00:17  time: 0.0767  data_time: 0.0013  memory: 663  \n",
      "08/26 18:37:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][730/909]    eta: 0:00:16  time: 0.0767  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][740/909]    eta: 0:00:15  time: 0.0766  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][750/909]    eta: 0:00:14  time: 0.0767  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][760/909]    eta: 0:00:13  time: 0.0766  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][770/909]    eta: 0:00:12  time: 0.0766  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][780/909]    eta: 0:00:11  time: 0.0765  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][790/909]    eta: 0:00:10  time: 0.0767  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][800/909]    eta: 0:00:09  time: 0.0766  data_time: 0.0015  memory: 663  \n",
      "08/26 18:37:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][810/909]    eta: 0:00:08  time: 0.0769  data_time: 0.0015  memory: 663  \n",
      "08/26 18:37:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][820/909]    eta: 0:00:07  time: 0.0770  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][830/909]    eta: 0:00:06  time: 0.0770  data_time: 0.0013  memory: 663  \n",
      "08/26 18:37:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][840/909]    eta: 0:00:06  time: 0.0769  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][850/909]    eta: 0:00:05  time: 0.0769  data_time: 0.0013  memory: 663  \n",
      "08/26 18:37:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][860/909]    eta: 0:00:04  time: 0.0772  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][870/909]    eta: 0:00:03  time: 0.0771  data_time: 0.0013  memory: 663  \n",
      "08/26 18:37:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][880/909]    eta: 0:00:02  time: 0.0770  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][890/909]    eta: 0:00:01  time: 0.0769  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][900/909]    eta: 0:00:00  time: 0.0769  data_time: 0.0014  memory: 663  \n",
      "08/26 18:37:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.91s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.65s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.235\n",
      "08/26 18:37:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.020 0.075 0.006 0.000 0.013 0.036\n",
      "08/26 18:37:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][909/909]    coco/bbox_mAP: 0.0200  coco/bbox_mAP_50: 0.0750  coco/bbox_mAP_75: 0.0060  coco/bbox_mAP_s: 0.0000  coco/bbox_mAP_m: 0.0130  coco/bbox_mAP_l: 0.0360  data_time: 0.0113  time: 0.0875\n",
      "08/26 18:37:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0200 coco/bbox_mAP at 1 epoch is saved to best_coco_bbox_mAP_epoch_1.pth.\n",
      ">>> Proses training selesai.\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 9: Mulai Training =====\n",
    "print(\">>> Memulai proses training...\")\n",
    "runner = Runner.from_cfg(cfg)\n",
    "runner.train()\n",
    "print(\">>> Proses training selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0367bfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INFO: Menggunakan checkpoint: ./outputs_swin_retinanet_deepfish\\best_coco_bbox_mAP_epoch_1.pth ---\n",
      "Loads checkpoint by local backend from path: ./outputs_swin_retinanet_deepfish\\best_coco_bbox_mAP_epoch_1.pth\n",
      ">>> Summary Deteksi: Total ikan terdeteksi = 0\n",
      ">>> Gambar hasil deteksi disimpan di: ./outputs_swin_retinanet_deepfish\\vis_outputs\\deteksi_result.jpg\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import inference_detector, init_detector\n",
    "from mmdet.visualization import DetLocalVisualizer\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "# --- [PENTING] Pilih Checkpoint Terbaik ---\n",
    "best_checkpoint_name = None\n",
    "if os.path.exists(cfg.work_dir):\n",
    "    best_ckpts = [f for f in os.listdir(cfg.work_dir) if f.startswith('best_') and f.endswith('.pth')]\n",
    "    if best_ckpts:\n",
    "        best_checkpoint_name = best_ckpts[0]\n",
    "\n",
    "if best_checkpoint_name:\n",
    "    checkpoint_path = os.path.join(cfg.work_dir, best_checkpoint_name)\n",
    "else:\n",
    "    checkpoint_path = os.path.join(cfg.work_dir, \"epoch_18.pth\")  # fallback\n",
    "\n",
    "print(f\"--- INFO: Menggunakan checkpoint: {checkpoint_path} ---\")\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(f\"ERROR: File checkpoint tidak ditemukan di '{checkpoint_path}'\")\n",
    "else:\n",
    "    # Patch kompatibilitas untuk load checkpoint\n",
    "    orig_load = torch.load\n",
    "    def torch_load_wrapper(*args, **kwargs):\n",
    "        kwargs[\"weights_only\"] = False\n",
    "        return orig_load(*args, **kwargs)\n",
    "    torch.load = torch_load_wrapper\n",
    "\n",
    "    # Inisialisasi model\n",
    "    model = init_detector(cfg, checkpoint_path, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Inisialisasi Visualizer\n",
    "    vis_save_dir = os.path.join(cfg.work_dir, 'vis_outputs')\n",
    "    os.makedirs(vis_save_dir, exist_ok=True)\n",
    "    visualizer = DetLocalVisualizer(\n",
    "        vis_backends=[dict(type='LocalVisBackend')],\n",
    "        name='visualizer',\n",
    "        save_dir=vis_save_dir\n",
    "    )\n",
    "    visualizer.dataset_meta = cfg.train_dataloader.dataset.metainfo\n",
    "\n",
    "    # Path gambar uji\n",
    "    img_path = 'dataset_final/test/dataset2_test__f3fc24dc6fe2db1c604d2eca5a5073e8.jpg'\n",
    "\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"ERROR: Gambar uji tidak ditemukan di '{img_path}'\")\n",
    "    else:\n",
    "        # Inference\n",
    "        result = inference_detector(model, img_path)\n",
    "\n",
    "        # Ambil jumlah ikan terdeteksi berdasarkan threshold\n",
    "        pred_instances = result.pred_instances\n",
    "        scores = pred_instances.scores.cpu().numpy()\n",
    "        labels = pred_instances.labels.cpu().numpy()\n",
    "\n",
    "        score_thr = 0.3\n",
    "        keep = scores > score_thr\n",
    "        num_detected = np.sum(keep)\n",
    "\n",
    "        print(f\">>> Summary Deteksi: Total ikan terdeteksi = {num_detected}\")\n",
    "\n",
    "        # Load gambar\n",
    "        img = mmcv.imread(img_path)\n",
    "        img = mmcv.imconvert(img, 'bgr', 'rgb')\n",
    "\n",
    "        # Visualisasi hasil dengan threshold\n",
    "        out_file = os.path.join(vis_save_dir, \"deteksi_result.jpg\")\n",
    "        visualizer.add_datasample(\n",
    "            name='result',\n",
    "            image=img,\n",
    "            data_sample=result,\n",
    "            draw_gt=False,\n",
    "            show=True,            # tampilkan popup\n",
    "            wait_time=0,\n",
    "            pred_score_thr=score_thr,\n",
    "            out_file=out_file     # simpan gambar hasil\n",
    "        )\n",
    "\n",
    "        print(f\">>> Gambar hasil deteksi disimpan di: {out_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ikan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
